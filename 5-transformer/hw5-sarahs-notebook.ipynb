{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1427869,"sourceType":"datasetVersion","datasetId":836206}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unidecode","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:59:48.463540Z","iopub.execute_input":"2024-06-09T13:59:48.464220Z","iopub.status.idle":"2024-06-09T13:59:56.908283Z","shell.execute_reply.started":"2024-06-09T13:59:48.464186Z","shell.execute_reply":"2024-06-09T13:59:56.907092Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Requirement already satisfied: unidecode in /opt/conda/lib/python3.10/site-packages (1.3.8)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:59:56.910478Z","iopub.execute_input":"2024-06-09T13:59:56.910804Z","iopub.status.idle":"2024-06-09T14:00:02.458497Z","shell.execute_reply.started":"2024-06-09T13:59:56.910775Z","shell.execute_reply":"2024-06-09T14:00:02.457408Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport numpy as np\nfrom rouge_score import rouge_scorer","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:02.460188Z","iopub.execute_input":"2024-06-09T14:00:02.460592Z","iopub.status.idle":"2024-06-09T14:00:02.466363Z","shell.execute_reply.started":"2024-06-09T14:00:02.460554Z","shell.execute_reply":"2024-06-09T14:00:02.465526Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import os, shutil\nimport re\nfrom transformers import BertTokenizer\nimport nltk\nimport regex\nimport unidecode\nfrom nltk.corpus import stopwords\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-09T14:00:02.467666Z","iopub.execute_input":"2024-06-09T14:00:02.467979Z","iopub.status.idle":"2024-06-09T14:00:02.593915Z","shell.execute_reply.started":"2024-06-09T14:00:02.467954Z","shell.execute_reply":"2024-06-09T14:00:02.593076Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"files = [\n         '/kaggle/input/persian-wikipedia-dataset/Persian-WikiText-6.txt',\n        ]\n\ntext = ''\nfor file in files:\n    with open(file, 'r', encoding='utf-8') as f:\n        text += (f.read())","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:02.596400Z","iopub.execute_input":"2024-06-09T14:00:02.596691Z","iopub.status.idle":"2024-06-09T14:00:03.543894Z","shell.execute_reply.started":"2024-06-09T14:00:02.596667Z","shell.execute_reply":"2024-06-09T14:00:03.542921Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"print(\"length of dataset in characters: \", len(text))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:03.545184Z","iopub.execute_input":"2024-06-09T14:00:03.545552Z","iopub.status.idle":"2024-06-09T14:00:03.551143Z","shell.execute_reply.started":"2024-06-09T14:00:03.545516Z","shell.execute_reply":"2024-06-09T14:00:03.550113Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"length of dataset in characters:  52303455\n","output_type":"stream"}]},{"cell_type":"code","source":"print(text[142000:145000])","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:03.552707Z","iopub.execute_input":"2024-06-09T14:00:03.553066Z","iopub.status.idle":"2024-06-09T14:00:03.563620Z","shell.execute_reply.started":"2024-06-09T14:00:03.553017Z","shell.execute_reply":"2024-06-09T14:00:03.562650Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"تون ها، به رنگ سنگی که ستون از آن تراش خورده اکتفا شده است، در حالی که در کاخ کوروش هخامنشی، تکنیک صیقل و تراش سنگ ها این امکان را به هنرمند داده است که از سنگ هایی با دو رنگ متفاوتِ سیاه و سفید استفاده کند. مهم ترین ویژگی در تمام محوطه ها و کاخ های هخامنشی در این آثار، استفاده از سنگ است، اما کاخ کوروش هخامنشی در چرخاب برازجان تنها نمونهٔ از معماری این عصر است که در بنای آن، هم از سنگ استفاده شده است و هم از آجر. استفاده از لعاب سیلیس روی کف بنا، نیز از دیگر موضوع های جالب توجه در این کاخ است که به عنوان اندود کف به کار گرفته شده و از نظر رنگ و جنس و روش ساخت، موضوع قابل تأمل است.» بیان این نکات کافی است بدانیم که چه اثر فاخر و منحصر به فردی در این منطقه از ایران وجود دارد.\n\nکشف سقف یکپارچه نانو تکنولوژی در کاخ کوروش آنچه در مورد اهمیت این اثر در حاشیه خلیج فارس نوشته شود، دال بر سیادت دریایی ایرانیان و سند مهم خلیج فارس است، مضافاً به این که شکوه و جلال و نقشه و پلان این قصر در این مکان، از ویژگی های خاصی برخوردار است که در سایر کاخ های هم زمان دیده نمی شود و این مهم را مخصوصاً در پوشش سقف سطح\n۴۰*۱۰متری جنوبی کاخ بعینه می توان مشاهده کرد، که از بزرگترین ابتکارهای معماری و ابداع های ساختمانی در ۲۵۰۰ سال پیش است که ارزش معنوی آن پس از گذشت قرن ها اینک به صورت شفاف و مستند آشکار شده که از یک نوع نانو تکنولوژی خاصی برخوردار است و دنیای به اصطلاح مترقی و متمدن امروزی در پی ساخت و ساز آن است. ساختن بتن سبک برای پوشش سقف مسطح در ۲۵۰۰ سال پیش، یعنی امی باور نکردنی و معجزه آسا که آزمایش های لابراتوری به آن جواب مثبت داده و غرور و افتخار هر ایرانی را در معرفی آن برمی انگیزد و توجه به پیشینه تاریخی بسیار کهن برازجان را نزدیک می کند. در سقف این کاخ که خود، نمونه عجیب معماری و مهندسی است، توانسته اند یک سقف با طول ۴۰ متر و عرض ۱۰ متر به صورت یکپارچه و صاف با ضخامت حدوداً ۵۶ سانتیمتر بسازند. می توانیم این سقف را به عنوان یکی از عجایب جهان محسوب بنماییم.\nساخت بتن سبک ۲۵۰۰ سال پیش در ایران\n\nبتن سبک برای اولین بار در جهان توسط کشور ما ساخته و در ۲۵۰۰ سال پیش در زمان هخامنشیان در کاخ کوروش در استان بوشهر در شهر برازجان مورد استفاده قرار گرفت. برای ساخت این نوع بتن، محصول از پیش ساخته شده را که با صمغ ترکیب نموده بودند، با استفاده از موادی مانند خون حیوانات و شاخ بز و گوسفند که از قبل ساییده شده بود ترکیب نموده و با کف حاصل بتن سبک را تولید می کردند. همچنین با کشف این اثر ملی که برای اولین بار توسط آقای دکتر علی اکبر سرفراز پدر باستان شناسی ایران کشف گردید می توان به صورت یقین اعلام داشت مخترع سیمان نیز، کشور ایران بوده و برای اولین بار در همان کاخ کوروش از آن استفاده گردیده است.\n\n\n\nعنوان مقاله: مایکل ای. جکسون\n\nمایکل آنتونی جکسون (متولد ۱۹۶۳)یک دانشمند کامپیوتر و مشاور رایانش خصوصی در لندن، انگلستان می باشد. وی همچنین یک محقق نیمه وقت در آزمایشگاه تحقیقاتی ای تی اند تی فلورهام پارک، نیوجرسی آمریکا و استادراهنمای دانشگاه آزاد انگلستان می باشد.\n\nجکسون در مدرسه هارو درس خوانده است، جایی که تحت تعلیم کریستوفر استراچی بوده و اولین برنامۀ کامپیوتری خود را نوشت. او در دانشگاه آکسفورد مطالعات کلاسیک (که در آنجا به \"نوابغ\" معروف است) خواند و با تونی هور، دانشجویی که ۲ سال از وی جلوتر بود، پیرو شدند. آن ها علاقۀ یکسانی نسبت به منطق داشتند که یکی از دروس آکسفور می باشد.\n\nد\n","output_type":"stream"}]},{"cell_type":"code","source":"len(text.split(' '))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:03.565250Z","iopub.execute_input":"2024-06-09T14:00:03.565586Z","iopub.status.idle":"2024-06-09T14:00:04.847438Z","shell.execute_reply.started":"2024-06-09T14:00:03.565550Z","shell.execute_reply":"2024-06-09T14:00:04.846450Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"9768905"},"metadata":{}}]},{"cell_type":"code","source":"text = text[:(len(text)//10)]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:04.848906Z","iopub.execute_input":"2024-06-09T14:00:04.849370Z","iopub.status.idle":"2024-06-09T14:00:04.877783Z","shell.execute_reply.started":"2024-06-09T14:00:04.849335Z","shell.execute_reply":"2024-06-09T14:00:04.876775Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"len(text)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:04.879142Z","iopub.execute_input":"2024-06-09T14:00:04.879456Z","iopub.status.idle":"2024-06-09T14:00:04.888894Z","shell.execute_reply.started":"2024-06-09T14:00:04.879431Z","shell.execute_reply":"2024-06-09T14:00:04.887957Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"5230345"},"metadata":{}}]},{"cell_type":"code","source":"len(text.split(' '))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:04.890012Z","iopub.execute_input":"2024-06-09T14:00:04.890316Z","iopub.status.idle":"2024-06-09T14:00:05.031251Z","shell.execute_reply.started":"2024-06-09T14:00:04.890293Z","shell.execute_reply":"2024-06-09T14:00:05.030193Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"1004072"},"metadata":{}}]},{"cell_type":"code","source":"chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.032665Z","iopub.execute_input":"2024-06-09T14:00:05.033017Z","iopub.status.idle":"2024-06-09T14:00:05.331172Z","shell.execute_reply.started":"2024-06-09T14:00:05.032977Z","shell.execute_reply":"2024-06-09T14:00:05.330110Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"\n !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ £§ª«¬­¯°±²¶¹»¼½¾ÉÖ×ØÙÚÛßàáâäåæçèéëíîñóôõö÷øüāăčēěğīıńōœřŠšūɑɒəɛɪʁʒʾʿˈ˓ˢ́̃ΑΔΚΠΩάήίαβδεζηθικλμνξοπρςστυφχωόύАБВКМНПУЮавеийклмнопрстуцчьёћԑԱԲԳԴԵԹԿՀՄՅՈՍՎՏՓաբգդեզէթիլխծկհղմյնշոչպջռստրցւփքְִַָֹּׁבדהוחיכמןנסרש،؛؟ءآأؤإئابةتثجحخدذرزسشصضطظعغـفقكلمنهوىئًٌٍَُِّْ٠١٢٣٤٥٦٧٨٩٪٫٬ٰٲٴپځچڕژکګگۀیە۰۱۲۳۴۵۶۷۸۹ਖਦਨਲਵਸਾਿੋაეიოუṛṭἈἘῖ ‍‎‏–—‘’“”†•…′″‹›ℓ™↑→⇔∇∈−∕√∩∪≈≘≝≠≡≤≥⊆⌠⟨⟩《》いがしたとのもろァアィイウェエオカガキクグコサザシジスズゼソゾタッツトドナニネハバビピフブプベペボマミャュユラリルレロンヴ・ー人作兵別唐団型大奇女娘子屯巨幻德心戦撃教査火点無燐特狐獣班種系肉草行調豆豌超進遇遭邪鎧隊食駐鶴黄개기내년늑대리머소속손송예우의중지진𐭍𐭑\n582\n","output_type":"stream"}]},{"cell_type":"code","source":"chinese_char = '種'\nindex = text.find(chinese_char)\nprint(\"chinese character found at index: \", index)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.332602Z","iopub.execute_input":"2024-06-09T14:00:05.332945Z","iopub.status.idle":"2024-06-09T14:00:05.343565Z","shell.execute_reply.started":"2024-06-09T14:00:05.332912Z","shell.execute_reply":"2024-06-09T14:00:05.342617Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"chinese character found at index:  1441039\n","output_type":"stream"}]},{"cell_type":"code","source":"print(text[index-200:index+200])","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.347463Z","iopub.execute_input":"2024-06-09T14:00:05.347753Z","iopub.status.idle":"2024-06-09T14:00:05.355259Z","shell.execute_reply.started":"2024-06-09T14:00:05.347729Z","shell.execute_reply":"2024-06-09T14:00:05.354299Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"ن ها ندارند و به همین دلیل، نحوه تکثیر آن ها هنوز برای انسان ها نامشخص است. اجساد تایتان ها بلافاصله پس از مرگ به سرعت به بخار تبدیل می شود. دمای بدن تایتان ها بالاست. برخی از تایتان ها را غیرعادی (奇行種 Kikō-shū) می نامند چون برخلاف دیگر تایتان ها عمل می کنند.\n\nتایتان غول پیکر(超大型巨人 Chō-ōgata Kyojin) (Colossal Titan)\nبزرگترین تایتانی که تا به حال دیده شده است. (با طولی نزدیک به ۶۰ متر) این تایتان ا\n","output_type":"stream"}]},{"cell_type":"code","source":"text = regex.sub(r'[^\\p{Arabic}\\s0-9]+', ' ', text)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.356270Z","iopub.execute_input":"2024-06-09T14:00:05.356543Z","iopub.status.idle":"2024-06-09T14:00:05.612553Z","shell.execute_reply.started":"2024-06-09T14:00:05.356519Z","shell.execute_reply":"2024-06-09T14:00:05.611748Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.613660Z","iopub.execute_input":"2024-06-09T14:00:05.613953Z","iopub.status.idle":"2024-06-09T14:00:05.897374Z","shell.execute_reply.started":"2024-06-09T14:00:05.613928Z","shell.execute_reply":"2024-06-09T14:00:05.896426Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"\n 0123456789 ءآأؤإئابةتثجحخدذرزسشصضطظعغفقكلمنهوىي٠١٢٣٤٥٦٧٨٩٪٫٬ٲٴپځچڕژکګگۀیە۰۱۲۳۴۵۶۷۸۹ \n87\n","output_type":"stream"}]},{"cell_type":"code","source":"print(text[142000:145000])","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.898839Z","iopub.execute_input":"2024-06-09T14:00:05.899326Z","iopub.status.idle":"2024-06-09T14:00:05.910865Z","shell.execute_reply.started":"2024-06-09T14:00:05.899286Z","shell.execute_reply":"2024-06-09T14:00:05.909807Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"انسته اند یک سقف با طول ۴۰ متر و عرض ۱۰ متر به صورت یکپارچه و صاف با ضخامت حدودا  ۵۶ سانتیمتر بسازند  می توانیم این سقف را به عنوان یکی از عجایب جهان محسوب بنماییم \nساخت بتن سبک ۲۵۰۰ سال پیش در ایران\n\nبتن سبک برای اولین بار در جهان توسط کشور ما ساخته و در ۲۵۰۰ سال پیش در زمان هخامنشیان در کاخ کوروش در استان بوشهر در شهر برازجان مورد استفاده قرار گرفت  برای ساخت این نوع بتن  محصول از پیش ساخته شده را که با صمغ ترکیب نموده بودند  با استفاده از موادی مانند خون حیوانات و شاخ بز و گوسفند که از قبل ساییده شده بود ترکیب نموده و با کف حاصل بتن سبک را تولید می کردند  همچنین با کشف این اثر ملی که برای اولین بار توسط آقای دکتر علی اکبر سرفراز پدر باستان شناسی ایران کشف گردید می توان به صورت یقین اعلام داشت مخترع سیمان نیز  کشور ایران بوده و برای اولین بار در همان کاخ کوروش از آن استفاده گردیده است \n\n\n\nعنوان مقاله  مایکل ای  جکسون\n\nمایکل آنتونی جکسون  متولد ۱۹۶۳ یک دانشمند کامپیوتر و مشاور رایانش خصوصی در لندن  انگلستان می باشد  وی همچنین یک محقق نیمه وقت در آزمایشگاه تحقیقاتی ای تی اند تی فلورهام پارک  نیوجرسی آمریکا و استادراهنمای دانشگاه آزاد انگلستان می باشد \n\nجکسون در مدرسه هارو درس خوانده است  جایی که تحت تعلیم کریستوفر استراچی بوده و اولین برنامۀ کامپیوتری خود را نوشت  او در دانشگاه آکسفورد مطالعات کلاسیک  که در آنجا به  نوابغ  معروف است  خواند و با تونی هور  دانشجویی که ۲ سال از وی جلوتر بود  پیرو شدند  آن ها علاقۀ یکسانی نسبت به منطق داشتند که یکی از دروس آکسفور می باشد \n\nدر دهۀ ۱۹۷۰  جکسون برنامه نویسی ساخت یافته جکسون  جی اس پی  را ایجاد کرد  در دهۀ ۱۹۸۰  به همراه جان کمرون توسعه سیستم جکسون  جی اس دی  را نیز ابداع کرد  سپس در دهۀ ۱۹۹۰  رویکرد قاب مشکل را ساخت  وی همچنین در همکاری با پالما زیو   ترکیب ویژگی های توزیع شده  که یک ساختار مجازی برای مشخص سازی و اجرای خدمات ارتباط از راه دور است را ایجاد نمود \n\nدر سال ۱۹۹۷  جکسون جایزه استیونس را برای روش های توسعه نرم افزار دریافت کرد \n\nپسر وی  دنیل جکسون نیز یک دانشمند کامپیوتر در مؤسسه فناوری ماساچوست می باشد \n\nجکسون چندین روش را ابداع کرده است  هر کدام از این روش ها از قبلی بخش بیشتری رو پشتیبانی کرده و ایده می سازد اما هنوز نسبت به روش بعدی ناقص است  با خواندن کتاب های وی به ترتیب  می توان به راحتی خط فکری وی را درک کرد \n\nبرنامه نویسی ساخت یافته جکسون  جی اس پی  اولین روش توسعه نرم افزاری بود که جکسون ایجاد کرد  این یک روش طراحی نرم افزار می باشد که در کتاب  اصول طراحی برنامه  به آن پرداخته شده است  جی اس پی طراحی برنامه های تکی را پشتیبانی می کند نه سیستم ها را \n\nتوسعه سیستم جکسون  جی اس دی  دومین روشی بود که جکسون ایجاد کرد  در این روش بر خلاف جی اس پی  سیستم ها نیز در کنار برنامه ها طراحی می شوند  جی اس دی خواناترین روش برای سیستم های اطلاعاتی است  اما می تواند به آسانی به توسعه سامانه نهفته بی درنگ تعمیم یابد  توسعه سیستم جکسون در کتاب  توسعه سیستم  بررسی شده است \n\nبررسی مشکلات یا رویکرد قاب مشکلات سومین روش ایجاد شده توسط جکسون است  این روش تلاش می کند تا تمامی نرم افزارها را پشتیبانی کند و نه فقط سیستم ها را  طرح اصلی این روش برای اولین بار در کتاب  احتیاجات و مشخصات نرم افزار  بیان شده و در  قاب مشکلات  به صورت کامل توضیح داده شد  اولین کارگاه جهانی پیشرفت ها و کاربردهای قاب مشکلات در بیست \n","output_type":"stream"}]},{"cell_type":"code","source":"n = int(0.9*len(text)) \ntrain_data = text[:n]\nval_data = text[n:]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.912140Z","iopub.execute_input":"2024-06-09T14:00:05.912435Z","iopub.status.idle":"2024-06-09T14:00:05.922738Z","shell.execute_reply.started":"2024-06-09T14:00:05.912410Z","shell.execute_reply":"2024-06-09T14:00:05.921819Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"class textdataset(Dataset):\n    def __init__(self, text, vocab, seq_len):\n        \n        self.vocab = vocab\n        \n        stoi = { ch:i for i,ch in enumerate(vocab) }\n        itos = { i:ch for i,ch in enumerate(vocab) }\n        self.encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n        self.decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\n        self.text = torch.tensor(self.encode(text), dtype=torch.long)\n        \n        self.seq_len = seq_len\n        \n\n    def __len__(self):\n        return len(self.text)\n\n    \n    def __getitem__(self, index):\n        i = index\n        if(index>=(len(self.text)-self.seq_len)):\n            i = (len(self.text)-self.seq_len) - 1\n        inpt = self.text[i:i+self.seq_len]\n        outpt = self.text[i+1:i+1+self.seq_len]\n\n        return inpt, outpt\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.923856Z","iopub.execute_input":"2024-06-09T14:00:05.924199Z","iopub.status.idle":"2024-06-09T14:00:05.935992Z","shell.execute_reply.started":"2024-06-09T14:00:05.924172Z","shell.execute_reply":"2024-06-09T14:00:05.935098Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"seq_len = 64\ntrain_dataset = textdataset(train_data, vocab=chars, seq_len=seq_len)\nval_dataset = textdataset(val_data, vocab=chars, seq_len=seq_len)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:05.937198Z","iopub.execute_input":"2024-06-09T14:00:05.937513Z","iopub.status.idle":"2024-06-09T14:00:07.208248Z","shell.execute_reply.started":"2024-06-09T14:00:05.937484Z","shell.execute_reply":"2024-06-09T14:00:07.207361Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:07.209413Z","iopub.execute_input":"2024-06-09T14:00:07.209707Z","iopub.status.idle":"2024-06-09T14:00:07.217025Z","shell.execute_reply.started":"2024-06-09T14:00:07.209682Z","shell.execute_reply":"2024-06-09T14:00:07.216191Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(tensor([38, 45, 47, 20, 45,  1, 44, 41, 20, 43, 46,  1,  1, 65, 20, 28, 33, 20,\n         46, 74,  1, 20, 30, 44, 45, 74,  1, 70, 74, 43, 74, 70, 74, 46,  0,  0,\n         65, 20, 28, 33, 20, 46, 74,  1, 20, 30, 44, 45, 74,  1, 70, 74, 43, 74,\n         70, 74, 46,  1, 21, 46,  1,  1, 20, 30]),\n tensor([45, 47, 20, 45,  1, 44, 41, 20, 43, 46,  1,  1, 65, 20, 28, 33, 20, 46,\n         74,  1, 20, 30, 44, 45, 74,  1, 70, 74, 43, 74, 70, 74, 46,  0,  0, 65,\n         20, 28, 33, 20, 46, 74,  1, 20, 30, 44, 45, 74,  1, 70, 74, 43, 74, 70,\n         74, 46,  1, 21, 46,  1,  1, 20, 30, 44]))"},"metadata":{}}]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:07.218208Z","iopub.execute_input":"2024-06-09T14:00:07.218565Z","iopub.status.idle":"2024-06-09T14:00:07.227378Z","shell.execute_reply.started":"2024-06-09T14:00:07.218530Z","shell.execute_reply":"2024-06-09T14:00:07.226480Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"4662816"},"metadata":{}}]},{"cell_type":"code","source":"print(train_dataset.encode(\"سلامم چطوری\"))\nprint(train_dataset.decode(train_dataset.encode(\"سلامم چطوری\")))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:07.228552Z","iopub.execute_input":"2024-06-09T14:00:07.228858Z","iopub.status.idle":"2024-06-09T14:00:07.238689Z","shell.execute_reply.started":"2024-06-09T14:00:07.228833Z","shell.execute_reply":"2024-06-09T14:00:07.237772Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"[32, 43, 20, 44, 44, 1, 67, 36, 47, 30, 74]\nسلامم چطوری\n","output_type":"stream"}]},{"cell_type":"code","source":"# def dataloader(val, batch_num, seq_size):\n#     if (val):\n#         dataset=val_data\n#     else:\n#         dataset=train_data\n    \n#     last_possible_idx =  len(dataset) - seq_size\n#     batch_start_idx = [random.randint(0,last_possible_idx) for _ in range(batch_num)]\n    \n#     inputs = []\n#     outputs = []\n#     for i in batch_start_idx:\n#         inpt = dataset[i:i+seq_size]\n#         outpt = dataset[i+1:i+1+seq_size]\n#         inputs.append(inpt)\n#         outputs.append(outpt)\n    \n#     return inputs, outputs\n\n# x, y = dataloader(True, 4, 5)\n# print(x)\n# print(y)     ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-09T14:00:07.239901Z","iopub.execute_input":"2024-06-09T14:00:07.240363Z","iopub.status.idle":"2024-06-09T14:00:07.249436Z","shell.execute_reply.started":"2024-06-09T14:00:07.240329Z","shell.execute_reply":"2024-06-09T14:00:07.248559Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=32,  shuffle=True, num_workers=2  )\nval_dataloader = DataLoader(val_dataset, batch_size=32,  shuffle=True, num_workers=2  )\n\ni = 0\n# Iterate over the dataloader to access your data in batches\nfor batch in train_dataloader:\n    i +=1\n    if (i== 10):\n        break\n    print(batch)\nprint(i)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:07.250536Z","iopub.execute_input":"2024-06-09T14:00:07.250881Z","iopub.status.idle":"2024-06-09T14:00:07.888089Z","shell.execute_reply.started":"2024-06-09T14:00:07.250847Z","shell.execute_reply":"2024-06-09T14:00:07.886839Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"[tensor([[74,  1, 20,  ..., 20, 74, 45],\n        [ 1,  1, 74,  ..., 28,  1,  0],\n        [ 1,  1, 77,  ...,  0,  0, 38],\n        ...,\n        [ 1,  1,  0,  ..., 33,  1, 44],\n        [ 1, 20, 45,  ...,  1, 44, 44],\n        [ 1, 44, 41,  ..., 74, 70,  1]]), tensor([[ 1, 20, 44,  ..., 74, 45,  1],\n        [ 1, 74, 70,  ...,  1,  0,  0],\n        [ 1, 77, 83,  ...,  0, 38, 45],\n        ...,\n        [ 1,  0,  0,  ...,  1, 44, 74],\n        [20, 45, 28,  ..., 44, 44, 70],\n        [44, 41, 20,  ..., 70,  1, 70]])]\n[tensor([[28,  1,  0,  ..., 74, 30, 74],\n        [ 1,  0,  0,  ..., 47, 30, 24],\n        [44, 74,  1,  ..., 44, 23, 47],\n        ...,\n        [ 1, 20, 74,  ..., 20, 43, 74],\n        [ 1, 77, 85,  ..., 31,  1, 74],\n        [41, 44,  1,  ..., 43, 44, 74]]), tensor([[ 1,  0,  0,  ..., 30, 74, 28],\n        [ 0,  0,  0,  ..., 30, 24,  1],\n        [74,  1, 21,  ..., 23, 47, 43],\n        ...,\n        [20, 74, 45,  ..., 43, 74, 23],\n        [77, 85, 77,  ...,  1, 74, 70],\n        [44,  1, 47,  ..., 44, 74, 46]])]\n[tensor([[70, 33, 23,  ..., 20, 45,  1],\n        [45, 31, 28,  ..., 21, 38, 28],\n        [46,  1,  1,  ...,  1, 21, 47],\n        ...,\n        [ 1, 20, 31,  ..., 74,  1, 33],\n        [45, 46, 20,  ...,  1, 38, 43],\n        [28,  1, 70,  ..., 46,  1,  1]]), tensor([[33, 23, 74,  ..., 45,  1, 44],\n        [31, 28, 46,  ..., 38, 28,  1],\n        [ 1,  1, 74,  ..., 21, 47, 28],\n        ...,\n        [20, 31,  1,  ...,  1, 33, 47],\n        [46, 20,  1,  ..., 38, 43, 74],\n        [ 1, 70, 46,  ...,  1,  1, 74]])]\n[tensor([[45,  1, 28,  ...,  1, 15, 44],\n        [74,  1, 79,  ..., 20, 43, 46],\n        [20, 30,  1,  ..., 67, 20, 65],\n        ...,\n        [15, 30,  1,  ..., 45, 47, 43],\n        [ 0,  0, 20,  ..., 81,  1, 32],\n        [ 0, 38, 45,  ..., 76,  1, 28]]), tensor([[ 1, 28, 74,  ..., 15, 44, 30],\n        [ 1, 79, 78,  ..., 43, 46,  1],\n        [30,  1,  1,  ..., 20, 65,  1],\n        ...,\n        [30,  1, 20,  ..., 47, 43, 47],\n        [ 0, 20, 44,  ...,  1, 32, 20],\n        [38, 45, 47,  ...,  1, 28, 30]])]\n[tensor([[21, 74,  1,  ..., 65, 45, 74],\n        [ 1, 46, 32,  ...,  1, 29, 46],\n        [ 1, 40, 30,  ..., 30, 47, 40],\n        ...,\n        [74, 70,  1,  ..., 20, 28,  1],\n        [45,  1, 20,  ..., 46, 44, 67],\n        [74, 33,  1,  ..., 20, 26, 74]]), tensor([[74,  1, 15,  ..., 45, 74,  1],\n        [46, 32, 23,  ..., 29, 46, 45],\n        [40, 30, 41,  ..., 47, 40, 23],\n        ...,\n        [70,  1, 44,  ..., 28,  1, 70],\n        [ 1, 20, 44,  ..., 44, 67, 45],\n        [33,  1, 32,  ..., 26, 74,  1]])]\n[tensor([[45, 28,  1,  ..., 21, 30, 72],\n        [70, 30, 28,  ..., 45, 44, 20],\n        [21, 47, 28,  ..., 82, 77,  0],\n        ...,\n        [30, 74, 70,  ..., 47, 30,  1],\n        [28, 45, 28,  ...,  0, 38, 45],\n        [46,  1, 44,  ..., 20, 45, 46]]), tensor([[28,  1,  1,  ..., 30, 72, 31],\n        [30, 28,  1,  ..., 44, 20, 74],\n        [47, 28,  1,  ..., 77,  0,  0],\n        ...,\n        [74, 70, 20,  ..., 30,  1, 32],\n        [45, 28,  1,  ..., 38, 45, 47],\n        [ 1, 44, 25,  ..., 45, 46,  1]])]\n[tensor([[23, 26, 28,  ...,  1, 32, 45],\n        [43, 23, 30,  ..., 44, 45, 37],\n        [ 1, 20, 45,  ..., 41, 20, 43],\n        ...,\n        [74, 43,  1,  ..., 74,  1, 32],\n        [38, 20, 23,  ..., 41, 30, 20],\n        [20, 23, 47,  ..., 32, 20, 43]]), tensor([[26, 28, 46,  ..., 32, 45, 20],\n        [23, 30, 20,  ..., 45, 37, 47],\n        [20, 45, 28,  ..., 20, 43, 46],\n        ...,\n        [43,  1, 47,  ...,  1, 32, 45],\n        [20, 23,  1,  ..., 30, 20, 30],\n        [23, 47, 30,  ..., 20, 43,  1]])]\n[tensor([[32, 28,  1,  ..., 31,  1, 33],\n        [32, 47, 30,  ...,  1, 72, 31],\n        [32, 45, 25,  ..., 46, 30,  1],\n        ...,\n        [30,  1, 33,  ..., 30,  1, 44],\n        [32, 45, 20,  ..., 30, 28, 31],\n        [44, 74,  1,  ...,  1, 20, 32]]), tensor([[28,  1, 44,  ...,  1, 33, 45],\n        [47, 30, 74,  ..., 72, 31, 74],\n        [45, 25, 20,  ..., 30,  1, 28],\n        ...,\n        [ 1, 33, 30,  ...,  1, 44, 38],\n        [45, 20, 74,  ..., 28, 31,  0],\n        [74,  1, 21,  ..., 20, 32,  1]])]\n[tensor([[74,  1, 28,  ..., 23,  1, 44],\n        [74, 47,  1,  ...,  1, 70, 46],\n        [74,  1, 47,  ..., 83, 76, 76],\n        ...,\n        [45, 47, 20,  ..., 26, 31, 21],\n        [ 0,  0, 38,  ..., 72, 23, 47],\n        [46,  1, 28,  ..., 46, 45, 28]]), tensor([[ 1, 28, 30,  ...,  1, 44, 23],\n        [47,  1, 21,  ..., 70, 46,  1],\n        [ 1, 47, 74,  ..., 76, 76,  1],\n        ...,\n        [47, 20, 45,  ..., 31, 21,  1],\n        [ 0, 38, 45,  ..., 23, 47, 45],\n        [ 1, 28, 20,  ..., 45, 28, 46]])]\n10\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_size = len(chars)\nseq_len = 64","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:07.889609Z","iopub.execute_input":"2024-06-09T14:00:07.889937Z","iopub.status.idle":"2024-06-09T14:00:07.894583Z","shell.execute_reply.started":"2024-06-09T14:00:07.889905Z","shell.execute_reply":"2024-06-09T14:00:07.893678Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\"\nif (not torch.cuda.is_available()):\n    device = 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:07.895897Z","iopub.execute_input":"2024-06-09T14:00:07.896209Z","iopub.status.idle":"2024-06-09T14:00:07.908395Z","shell.execute_reply.started":"2024-06-09T14:00:07.896183Z","shell.execute_reply":"2024-06-09T14:00:07.907412Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size, embed_dim, dropout=0.0):\n        super().__init__()\n        self.key = nn.Linear(embed_dim, head_size, bias=False)\n        self.query = nn.Linear(embed_dim, head_size, bias=False)\n        self.value = nn.Linear(embed_dim, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(seq_len, seq_len)))\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,C)\n        q = self.query(x) # (B,T,C)\n        # compute attention scores \n        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1) # (B, T, T)\n        wei = self.dropout(wei)\n        # perform the weighted aggregation of the values\n        v = self.value(x) # (B,T,C)\n        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n        return out\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, num_heads, head_size, embed_dim, dropout = 0.0):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size, embed_dim, 0.2) for _ in range(num_heads)])\n        self.proj = nn.Linear(embed_dim, embed_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out\n\n\n\n\nclass FeedFoward(nn.Module):\n    def __init__(self, embed_dim, dropout = 0.0):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(embed_dim, 4 * embed_dim),\n            nn.ReLU(),\n            nn.Linear(4 * embed_dim, embed_dim),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n    \nclass Block(nn.Module):\n    # Transformer block\n\n    def __init__(self, embed_dim, n_head):\n        # embed_dim: embedding dimension, n_head: the number of heads we'd like\n        super().__init__()\n        head_size = embed_dim // n_head\n        self.sa = MultiHeadAttention(n_head, head_size, embed_dim, 0.2)\n        self.ffwd = FeedFoward(embed_dim)\n        self.ln1 = nn.LayerNorm(embed_dim)\n        self.ln2 = nn.LayerNorm(embed_dim)\n\n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:07.909729Z","iopub.execute_input":"2024-06-09T14:00:07.910021Z","iopub.status.idle":"2024-06-09T14:00:07.928414Z","shell.execute_reply.started":"2024-06-09T14:00:07.909995Z","shell.execute_reply":"2024-06-09T14:00:07.927295Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"class LLM(nn.Module):\n    def __init__(self, vocab_size, embed_dim, n_layer, n_head):\n        super().__init__()\n        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n        self.position_embedding = nn.Embedding(seq_len, embed_dim)\n        self.blocks = nn.Sequential(*[Block(embed_dim, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(embed_dim) # final layer norm\n        self.lm_head = nn.Linear(embed_dim, vocab_size)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        # idx and targets are both (B,T=seq_len) tensor of integers\n        # T=seq_len and C=embed_dim\n        tok_emb = self.token_embedding(idx) # (B,T,C)\n        pos_emb = self.position_embedding(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C)\n        x = self.ln_f(x) # (B,T,C)\n        logits = self.lm_head(x) # (B,T,vocab_size)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # crop idx to the last seq_len tokens\n            idx_cond = idx[:, -seq_len:]\n            # get the predictions\n            logits, loss = self(idx_cond)\n            # focus only on the last time step\n            logits = logits[:, -1, :] # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:07.929719Z","iopub.execute_input":"2024-06-09T14:00:07.930028Z","iopub.status.idle":"2024-06-09T14:00:07.944358Z","shell.execute_reply.started":"2024-06-09T14:00:07.929992Z","shell.execute_reply":"2024-06-09T14:00:07.943372Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split, dataloader in zip(['train', 'val'], [train_dataloader, val_dataloader]):\n        losses = []\n        num_batches = 50\n        for i, (X, Y) in enumerate(dataloader):\n            X=X.to(device)\n            Y=Y.to(device)\n            logits, loss = model(X, Y)\n            losses.append(loss.item())\n            if i + 1 >= num_batches:\n                break\n        out[split] = np.array(losses).mean()\n\n    model.train()\n    return out\n\nmodel = LLM(vocab_size, embed_dim = 32, n_layer=4, n_head=4)\nm = model.to(device)\n# print the number of parameters in the model\nprint(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\nlearning_rate=1e-3\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\niterations=10\nfor iter in range(10):\n    if iter % 3 == 0 or iter == iterations - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    num_batches = 500\n    for i, (x, y) in enumerate(train_dataloader):\n        x=x.to(device)\n        y=y.to(device)\n        # evaluate the loss\n        logits, loss = model(x, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if i + 1 >= num_batches:\n            break\n\n# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(train_dataset.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:06:42.844608Z","iopub.execute_input":"2024-06-09T14:06:42.844991Z","iopub.status.idle":"2024-06-09T14:09:10.979175Z","shell.execute_reply.started":"2024-06-09T14:06:42.844962Z","shell.execute_reply":"2024-06-09T14:09:10.977966Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"0.058199 M parameters\nstep 0: train loss 4.6631, val loss 4.6507\nstep 3: train loss 2.2081, val loss 2.5195\nstep 6: train loss 1.9530, val loss 2.3411\nstep 9: train loss 1.8680, val loss 2.2472\n\nاثضالی حراط یاص رابا کند ندر بشه شد سیاد و که اثثته  زبا شخیتر شورگی او شسه راندین ۱۹ خورض  به دالایت او در دهمت  آو صرب امننیخی و وجه دی۳ ا حسهر حرامم موبلا ۲۷۵ میل بتر مرحدی  درنشک در به جور حزن محصد    نیاز  را زشدماران علام منا خوام  شوده اننست نگرامعی نوزه ارست  هانیهانگیر زمنداد  هست ایده  پلاقه تجار های درآن در از گرف خواله ژوازی عن سیل تو جمتات دادامنی به میروجه ای کردگرگی  شدیربان شباعال می شون اصه تند  شاط که بانشد \n\n\n\n\nعنوان مقال  اساس کلادی \n این شدندهای ۱۹۶ یک که طول آن 2۴۲۱  \n\n\n\nعنوان مقاله  جباندسته منند بانرتراری بارم به دکی ساد  تمی کلی بویان اولد  به به هسبریگ شه با        آی ب۲۴  بی۰۰۱ میلادی کند که پرسسش  ۱۹۳۵  متوع وی هونه  هر   آسرشگاه منبازاه شده کند خالات ترطای به اشدل \n\n۳۸۱ اچ هر   یموک چیامر\n\n\nآرزفادیل گیردره اس  گرستگیه شاحده     نیاز خوستم در که اراه  ۱۸۰۰\n\nنظرن سنای مویر چشکون در هد  که بسین زیرن سنیا اچ مجمی غی فدهری ای کرگ باشد 19 \nبی ختراف اجر کنجا مداردرکران زها بسطاد  و و صنداد دم به این شترالیدی سنرا حساف ستوت  تخلانیشی رارد مرحینده دار دانه در سالبکات تعلب که در ۱۹۱۳ متا نوزند و و سازد  ۴ در فرحم دهر گد ای از آطل بی یود که ی در به زمیربان که پست استد  ۸۵ لاز سال ۱۹۳۵ دوم سال ۱۸۰۳ شد خود \n\n\n\n\nعنوان مقاله  اچ اس اس س ۷۵ \n\nاچ چ واس ی ی ۶۶ \n\nیواس س ۷۹ اس ی ۱۸۱\n\nیواس اس اس  اس زی آ۳۶ \n\nیوان  اس ۱۳ اچ۰۲  ی یکلا کنوزه تیلیط\n\n\n\nعنوان مقاله  دی اوی محمرسپیل در لین پاین اژده و خود میلی جمصده در داد آرا مدرةه لناقیضی  \n\nبه    توزهره زمین می شودده به حکی یر بازه سال ۲٬۰ جمی اصره شیر به درارد آن محران بار یرده  و در ایلورانی از و دست آن اسامگاه  یاز معثل به طلمخت نتصوغ به ارایده به نها عو پنای از گیر کشاوخت بارنی زدر  یاملان  لیونند فریلیت  زوانجیی تراب فق طلوف در مواد  به علاپل مهورد های ایر با می اسات که کواد بازه مهم کان فال بر در  از منطقیقای مقتب و امرف بخشیره سصلاخت شدگاه هاست از با با صوره ها در نوقار هست پی های همچنه شده هماث می دگروت مقد چندگ یا واصعه سولب در استاریل  دادر کان خواری به گای سال ۱۹۴ میلادی زیردن و بند \n\nاقله درداتلان و خاکتمانینی ساکرت در سال ۱۰۱۹ سال تی ک کشتی بود است که مجد  ۰۹۰۵ شد \n\n\n\n\nاچ ام اس س الیندابت که طول آن \n","output_type":"stream"}]},{"cell_type":"code","source":"iterations=20\nfor iter in range(iterations):\n    if iter % 3 == 0 or iter == iterations - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    num_batches = 500\n    for i, (x, y) in enumerate(train_dataloader):\n        x=x.to(device)\n        y=y.to(device)\n        # evaluate the loss\n        logits, loss = model(x, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if i + 1 >= num_batches:\n            break\n\n# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(train_dataset.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:14:31.694273Z","iopub.execute_input":"2024-06-09T14:14:31.694657Z","iopub.status.idle":"2024-06-09T14:19:16.506241Z","shell.execute_reply.started":"2024-06-09T14:14:31.694624Z","shell.execute_reply":"2024-06-09T14:19:16.505088Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"step 0: train loss 1.7144, val loss 2.1038\nstep 3: train loss 1.7193, val loss 2.0892\nstep 6: train loss 1.6838, val loss 2.0754\nstep 9: train loss 1.6624, val loss 2.0589\nstep 12: train loss 1.6766, val loss 2.0456\nstep 15: train loss 1.6644, val loss 2.0242\nstep 18: train loss 1.6225, val loss 2.0118\nstep 19: train loss 1.6381, val loss 2.0163\n\nسیتفاحی نشان پای  یا رسنان ایالات متحده آمریکا بود \n\n\n\n\nعنوان مقاله  یواس دی پییوند  ویپنی سنای آذریک با سرقه ايی آتوز تی کماری  آن  بود که طول آن می باشد  \n\n\nعنوان مقاله  جلس دراف ایراکان حدوتر سناتور ایالات متحده آمریکان هشته در برای عضو حاف دمور شود  اجس از جموره  این این طور بلق عصدم همسمی نب شهر معرکزی آها خاس نویل گر سیاسی ایجاد با جینست گیرهای درندین فرگاتانش وی از اثی اارسام شوکرندند  بایاض الش بین کل انتشای آی ویژه شاختن    مهنطق عارکثیر دروه پوه به غا زوده این گزن  ۲٫۹۸۲ تنه به و پیه\n\nتبت این جایش اتاد پراهسلی متنین ۹۱۰۰ قادواون به ۱۰ قصاب تعالف است \nدر بتاید وماند به مصرا یاللت تامیده شبکند \n\nپاهلیسل  پمپیشنگی اول ممی تواب تا متأث ذزیرات حلوبر معایر غبه همرین باطی و چنیات بود کامات   کغربند 4 یا ۱۵۵ \n\nیواس اس اس منین  پی۱  ای انگ تی \nسی دی ساخته است که است  این کشتی در سال ۱۸۶ ساخته شد  وی در جهم باکار بیشترین مجنظ پذیر لشور یافری اسکه   از بالکو است  به معمام اسب که پنگل پذکتو مجموع توع که منفایتی \n\nیمن لج رسبط\nفاصع گیرش کارند و  رموشوهاد هم رستندند کار انرژه استفاده او سازه دوس عوت یابت \nاوام هتچای\nدیلونگریرن کل دیه ۱۷۷ حات جموین خاکتپی در سال ۱۸۸۷۵۶ ساخت \n\n\n\nعنوان مقاله  ایپا لمنده فیلتلمیچین\n\nداجعای مؤثبه  جمه این منحده شده  أموضو او سر ضلای مقعبارام مقاقعه داشت بد \nدوارای گلیل قرب می کا کشت کم در امین ها ایالاتوک کچیګده که ملاین انجمه ایران دیگربا امیه برینگار و حرای امام دورکودپلن به خایر فا لاوحن می شود که هیشتراد بق ه می کنند \nبه لنیاتان دیلم پیی شیلعیلاتی عفام امتماری دکه در سنابود \n\n\nدورهاینون وردگیر هایی خند  تدراظت کار می  لهاههه  موساتون و در فین ها با شکثرهش قالت 2622 مانتقلای را می و باردنا درورایل سالابی استفاده می شود  در سال ۱۹۱۰ فصلی در نهاست آبانین  و در نمی است  سال ۱۹۲۷  یک که کمال متحده آمریکا بود \n\n\n\n\n\nعنوان مقاله   را در سال نتشکلن رئالاه  ای بی کاکس  ۴ \n\nگردی  نام00 سالات ۲۰۰۵ و کارهوتنیسبا   جملاتوکوس مسگره  جاز ریاد های های تورها هر کند  فارسلمتاتنی   کتوا حوت در این که در فضهفه به اصور مریبا پیه\n\nعاجش دسر در سیاز این سناتور نگرفت سازمی و راده افزار اطلاعت ثواتره این متشماتکریت ارومه را به به با صففحمون درگذیر کلیسورکست یواگریش\n","output_type":"stream"}]},{"cell_type":"code","source":"iterations=20\nfor iter in range(iterations):\n    if iter % 3 == 0 or iter == iterations - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    num_batches = 1000\n    for i, (x, y) in enumerate(train_dataloader):\n        x=x.to(device)\n        y=y.to(device)\n        # evaluate the loss\n        logits, loss = model(x, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if i + 1 >= num_batches:\n            break\n\n# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(train_dataset.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:21:20.831645Z","iopub.execute_input":"2024-06-09T14:21:20.832210Z","iopub.status.idle":"2024-06-09T14:30:05.826575Z","shell.execute_reply.started":"2024-06-09T14:21:20.832160Z","shell.execute_reply":"2024-06-09T14:30:05.825364Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"step 0: train loss 1.6291, val loss 2.0265\nstep 3: train loss 1.6056, val loss 1.9952\nstep 6: train loss 1.6199, val loss 1.9957\nstep 9: train loss 1.5941, val loss 1.9944\nstep 12: train loss 1.5806, val loss 1.9623\nstep 15: train loss 1.6055, val loss 1.9614\nstep 18: train loss 1.5757, val loss 1.9599\nstep 19: train loss 1.5846, val loss 1.9691\n\n\nجعادل و خاستم منوز اسکس  در دی از صدی  این مانتیعان پیمکند و بلاعه می کنند  در نگار چه به تهرالیس حای یافت  با محیقه بنجه از شده بسیان بلا بهی \n\n\nکحوبوم ولی را ۱۹۶۹ میلادیت سناتور ایالت ناآن در تأمی اینی بن نتیفاع شمال  سیسوم ونسی ها فیلم به ا راه مرکزش نصاحی محروبی مشکل باطوح جورتری صاعت و انتر به قرا ترینیخ فیزور این وی براد را دکتار تغییلیت این در سام گیزاردگان دره سال ۲٫۴۷ صداد از پهوان  نماه گرزاری نیم جهان بین بسیار به این ایریخت اخلعاط  یکی طی  جیز ایلن کتر ۱۷بلات ویار به کشرت استفاده بود  رئینان استسط می ملی ژاننگ است  ارمن 23  صحیحا دیگرا کردند \n\nرونای لاژی  توانات ۱۰ بیکی کوئیا مرت آمده و درک  در دس  این عنواله باشد ولی در سال ۲۰۱  ۱۹۸۵ تا ۱۹۶۹ آوالن  \n\nاس اف وشمپ  و تراسی  ۱۸۴۰   یک محمادت این رس که شهرت می کشتبان درکوری های اوسیه از \n\n\nپلنیا ها اینکومیونه  است  سازبی جغربرای پوکوی در سالیزه کشور حملیت آرافت امر کند در این شکستنان انگل  در سال ۱۹۹۹ میلادی سناتور سابقبت  سیابای فقتی جوزن جداده قل  ۱۹۰۷ تأثیر مصلحیق در آن پنرزندی داده \n\n\n\nعنوان مقاله  بهترویت در اناخه است  شد  ول ۱۸۶۰ تا ۱۹۳ میلادی سناتور ایالت این سئوسی  پی بازگان  توا آنین رومانن داعته آن پوس وجهش  بی بعدان را پهلید  از اتد  دیورس می یا موجینی بود و به هایش  از سهای ایریک خاندها اشیسی درت وجاد  خوایرن قونت موجود می شود تا شاه از سروش نیز هسالات  3  شده است \n\nپس اضمود آدی ضرین جنجاوتر حقوق اسلی یل ماییبریفر است که برم در  دوقه گردی کارد بسته ۱۰۰۰ باعثی خود هنرک مجنطقه بر الوتیتر ریز انتقاتشی های نیز مرعارخ روش ترکار بود  \n\n زیمان بین و گازبانه چند  شوه می هند و پینگ ویژن ساید و ی جنتبار در سال ۱۶۷ تا ۱۸۷۵ میلادی سناتور ایالت تفاولولیی در سال ۱۹۳ مادبا کرد  پیفه این ژوی بزپس علمانه  یال عوبوب رزمی کمی  کنند  از پی پی تساف معرفه در به جست کرد وجوی بینات با هر شودرف صوچه  اتخابت ها  ثریاری از دانشکد  برای ااجازار ارست استفاده ارائه می شود و از طلات هنگ منجمن تشکلیه سالصه شکستر در پذرض موضوع  مجرحی گرفتند به پیش ناسن نظار و از را دهند درای انجان داشتی و رفتانه از دقری های ایوجوع به واربر برودندان ۱۴  میلرد ماستان  سنگینی خاون خالاب ترکیب  عبعد  بربر  ابنریا هستن دیگر بتیان می شود  زیبای نایف \n","output_type":"stream"}]},{"cell_type":"code","source":"iterations=50\nfor iter in range(iterations):\n    if iter % 3 == 0 or iter == iterations - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    num_batches = 1000\n    for i, (x, y) in enumerate(train_dataloader):\n        x=x.to(device)\n        y=y.to(device)\n        # evaluate the loss\n        logits, loss = model(x, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if i + 1 >= num_batches:\n            break\n\n# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(train_dataset.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:56:02.100026Z","iopub.execute_input":"2024-06-09T14:56:02.100455Z","iopub.status.idle":"2024-06-09T15:17:21.674102Z","shell.execute_reply.started":"2024-06-09T14:56:02.100411Z","shell.execute_reply":"2024-06-09T15:17:21.672974Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"step 0: train loss 1.5806, val loss 1.9445\nstep 3: train loss 1.6065, val loss 1.9379\nstep 6: train loss 1.5512, val loss 1.9347\nstep 9: train loss 1.5888, val loss 1.9559\nstep 12: train loss 1.5602, val loss 1.9285\nstep 15: train loss 1.5450, val loss 1.9255\nstep 18: train loss 1.5674, val loss 1.9127\nstep 21: train loss 1.5402, val loss 1.9198\nstep 24: train loss 1.5717, val loss 1.8985\nstep 27: train loss 1.5476, val loss 1.8953\nstep 30: train loss 1.5433, val loss 1.8985\nstep 33: train loss 1.5311, val loss 1.8833\nstep 36: train loss 1.5290, val loss 1.9063\nstep 39: train loss 1.5394, val loss 1.8918\nstep 42: train loss 1.5321, val loss 1.9160\nstep 45: train loss 1.5366, val loss 1.8979\nstep 48: train loss 1.5131, val loss 1.8851\nstep 49: train loss 1.5461, val loss 1.8817\n\n\n\n\n\nعنوان مقاله  اچ ام اس کانفت  ۱۸۴ \n\nاچ ام اس ارسر  آب ۱۷۸  یک کشتی است که طول آن می باشد \n\n\n\nعنوان مقاله  رلیسک\n\nمئیس اف الیجی با  پی استون   تبکی فضایه  سرل نکه نزد آمبیا اختلار تا بادولت یک  محسوبل از به سازنه از تهرایی و آینها  ترکتان متولیسونایژ بنای اسلی  دادگاه های به کترو سخن در سال ۱۹۴۴ک از چایستان موارسه گبرد \nاز سرزمی برگشتن  تبرر به اسراتکونی آبهنس  سنگ تیکان آن   پزیکلوس کرد \nکلیلا  های   گروهای حردومه  ژورت به سند با ئرام است که بیمارساسی رساندگی در نظیم داتثرت می خوانوند و می یک ویتر که حسائوت  آرگال ها تبرای گرتازه می باشد  گره که کلاه هری در سنای ایالات متحده آمریکا بود \n\n\n\n\n\nعنوان مقاله  حافل ۲۰۰ ژوئیو  آنجا یک از ۲۵۵ \n\nادر مرکع الاح منشری به ترک اسپور فوتبام ۴۶۰۳ منسکان  اجرا بازدان آن درخش آنجان مسطح سبیات امات اوز ساخته آی کار به از معمامل می تواند \n\nنخستی می ترامی همچوط نسند جود ایت کنگاه بیعی ده است    اکثرزه در آیر ابعداد خود دسترسین مو سال از به ثدر گذر غیر شده و یعنی جامعه کارآوربوس کاهمن نامه موزیاری به در آن آزای  بازان اطلاعان روررده ای جا سازگان پالها را به بیژریافیت  از سای در تفعاد سازی  او ممبات می گو که در هرساک تا اجبه این ورتی فرم نونی که نشانه آیت خدمت \n\n\n\nعنوان مقاله  های  وسا  عبعامد جامع محسخه کابر\n\nاشاهد میلادیاار متحده آمریکای یک کشتی به فرضی  و نوست از زوب و طا۲۱  در سال ۱۹۷۷ تاسط و به هرکسته در کوف ای نی دینا برایای عرضای سازمانه آید نام سیا اشند  برابرد کیکنی پایزشی است  در حوزهایت کتب ها عدلام  همنشک می پس ازدند  تأثیر کامپیون  ۱۳۶۴ تهرای میزان کار های موسط شمی اسلط اساسه نبردیار و حاث ذارنستان  اذق ها و این و های پژوخ ایالن بیماری منتشر ارتبار نسقد کرد  یا شاعش دروید می کنند \n\nترا عل شاخصی را کردندگانه ضرتفاعیل برای نوشته  برایی پس به دام این ایز عضو   تحوجرازه سلی کردفان نفع جنگ مودی تست \n\nرئیس و زیرستی می تواناد  ۱۸۸۸ \n\n\nترت  انام آشه ها  در سه است  از آن دهه می شود و حسابد ۱ آتارانی افزود  اخداری ۵۰ اکلیونیز  نشانه پرا داروف  تیاب در سپتازش و برای رشد فصلیت \n\n\n\n\nعنوان مقاله  تلک آهپشم در بالا  تویگوری السکول وارارت طح ساعی این کرد سلسعتور بر رقلاف قائه کنند  صلقه راهنر به کم ممی کارفانیا بود  و لازر و اشگاه در حسود\n","output_type":"stream"}]},{"cell_type":"code","source":"iterations=30\nfor iter in range(iterations):\n    if iter % 3 == 0 or iter == iterations - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    num_batches = 1000\n    for i, (x, y) in enumerate(train_dataloader):\n        x=x.to(device)\n        y=y.to(device)\n        # evaluate the loss\n        logits, loss = model(x, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if i + 1 >= num_batches:\n            break\n\n# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(train_dataset.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T15:35:23.074990Z","iopub.execute_input":"2024-06-09T15:35:23.076005Z","iopub.status.idle":"2024-06-09T15:48:52.543130Z","shell.execute_reply.started":"2024-06-09T15:35:23.075964Z","shell.execute_reply":"2024-06-09T15:48:52.541853Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"step 0: train loss 1.5329, val loss 1.8906\nstep 3: train loss 1.5365, val loss 1.8949\nstep 6: train loss 1.4869, val loss 1.8834\nstep 9: train loss 1.4844, val loss 1.8845\nstep 12: train loss 1.5093, val loss 1.8618\nstep 15: train loss 1.5079, val loss 1.8829\nstep 18: train loss 1.5338, val loss 1.8747\nstep 21: train loss 1.5116, val loss 1.8831\nstep 24: train loss 1.5013, val loss 1.8819\nstep 27: train loss 1.5419, val loss 1.8846\nstep 29: train loss 1.5029, val loss 1.8787\n\n\nپی ک سناتور سابق عضو حزب دموکرات ایالت اممرده ای را یکملز ژوئی چشمنی های هنگزیدرایی محلات است  تراک در ۱۳۰  سال ۱۸۱۲ میلادی بود که طول آن بود  این کشتی در سال ۱۸۴۴ ساخته طول آن می بایلات میلاد دهد  سختت وجود که طول آن بود \n\n\n\nعنوان مقاله  فوات وی رسوم عمل اب در سپس امورد  ۵۹۹ هجهان سازی علیف او تاوئیه می داند \n\nفنای مروش تحقیقات محمدعه خداده خنط محیط نیابد به نوع مصرف برای پوس نشای عبدری خم کابکرنان علدان قمومت عنقلاع هموا به رای آی ستانیما به عنشی یک در است ارمرد و برای است \n\nدوم دانشگیت طبق دمان یشتری به طول آن بود  این کشتی در سال ۱۹۱۹ ساخته شد \n\n\nعنوان قرار داله  قصط نادر سوری مشهورهای نیز حضلح رای بدحی آموزش  شواد \n\nمورات قیال  بناوهای جقر کلیوند\n\nسیسم رانپوری حقل است عضوری ست  و لبی مختل گیان کیداری با و دو انتک و در سلطنان این و مکس اسط می باشد و با مدا سیاسی به معموس توسط می خرد بناشد \n\n\nدواکت بترزر دستر تابور نیز راحت سبکدام خون هاست و عمومی موست بارپر بر دو او ۱۰۵ نی کنده روز یا دانسه  و هود ۱۷۷ ۱۸۱۱   بز  ۱۹۱۳ کدری\n\n\n\n\n\nعنوان مقاله  یواس هنگ یک زیر ای کسفکر  کاکو سور صرتی های و تنتبان جناورری تعوظ گویرد \n\nیواس از راک متوف شود  نیا ساخته همه انتخانه تعد  در سال ۱۸۶۱ دیشترافی نظر شعه ۱۹۴۶ دموکر منادل و رقرآه محدشاهی بوده استان و است   این کشتی بود \n\n\n\n\nعنوان مقاله  نبوق تاردو و هیئل\n\nچارتز ۳ جیباسی یوجان رفت اوره سیستم است \n\n۳ بر ۱۳۰ ۱۹۰۳ مقاله  ۱۴۴۸ ۱۳۹۱ با  این نام ای داشته و آی آمد \n\n\n\n\nعنوان مقاله  یواس جا  تودر سناتور سابق عضوی این در جدا سفت سینات رندیانی در سال ۲۰۸۳ بود که طول آن بود  این کشتی در سال ۱۹۴۰ ساخته شد \n\n\n\nعنوان مقاله  اچ اچ اطللان می ای بود \n\nرواب ساخ ایدین سرعت ساوی عرف پوه  اسلامیون سناتور آر ایال ۱۸۶  یک کشتی است که طول آن بود  این زیردریایی در سال ۱۸۸۹ ساخته شد \n\n\n\nعنوان مقاله  اچ اسپائله\n\nاچ ام ام یوبی ۱۰۷  شرمایش  هیزی   ۲۲۰۷  یک کشتی بود که طول آن بود  این فیلم  می برنان است که دزدیان این محدود  پس ارمنی از گاتا پردگیری خوا با قدافات ها وزی خدمان زیرده کاری آگویرها های است  خاطرات بویع  در اینک و لاشگران به آن مبو فرزاریان صنب بی خود  هیزی شهرد و در اینداز  خصوطایر خوطرهای و جنام فرم شورای  رایافی  در اتریان کرد و بوده از قسم کان\n","output_type":"stream"}]},{"cell_type":"code","source":"print(m.generate(context, max_new_tokens=2000)[0].tolist())\nprint(train_dataset.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T16:14:56.895208Z","iopub.execute_input":"2024-06-09T16:14:56.895611Z","iopub.status.idle":"2024-06-09T16:15:30.022341Z","shell.execute_reply.started":"2024-06-09T16:14:56.895575Z","shell.execute_reply":"2024-06-09T16:15:30.021282Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"[0, 0, 45, 47, 30, 1, 28, 30, 1, 37, 30, 40, 23, 1, 20, 47, 1, 28, 30, 1, 32, 23, 20, 30, 1, 15, 45, 1, 28, 40, 23, 1, 70, 46, 1, 33, 27, 34, 74, 23, 1, 1, 47, 1, 74, 70, 74, 1, 20, 31, 1, 33, 21, 70, 46, 1, 20, 31, 1, 38, 44, 47, 43, 1, 45, 37, 30, 1, 20, 41, 28, 20, 44, 1, 27, 47, 28, 1, 30, 74, 20, 45, 74, 1, 21, 46, 1, 41, 20, 44, 31, 21, 1, 20, 45, 28, 20, 31, 46, 1, 72, 30, 1, 44, 26, 43, 1, 46, 20, 1, 28, 30, 1, 20, 28, 31, 20, 30, 1, 44, 74, 1, 72, 74, 30, 28, 1, 0, 0, 47, 38, 28, 1, 46, 20, 74, 1, 65, 20, 74, 28, 45, 1, 46, 20, 74, 1, 20, 25, 30, 20, 1, 1, 20, 32, 23, 1, 20, 74, 45, 1, 21, 46, 1, 65, 40, 23, 46, 1, 21, 20, 1, 21, 30, 20, 74, 1, 1, 44, 26, 43, 46, 1, 44, 26, 20, 40, 37, 46, 1, 21, 20, 33, 28, 1, 1, 70, 20, 30, 46, 1, 20, 74, 45, 1, 20, 45, 23, 41, 20, 43, 1, 1, 15, 21, 74, 28, 1, 1, 1, 20, 31, 1, 38, 45, 47, 20, 45, 1, 32, 20, 45, 20, 23, 47, 30, 1, 28, 30, 1, 32, 20, 21, 41, 1, 38, 35, 47, 1, 26, 31, 21, 1, 28, 44, 47, 70, 30, 20, 23, 1, 20, 74, 20, 43, 20, 23, 1, 44, 23, 26, 28, 46, 1, 15, 44, 30, 74, 70, 20, 1, 21, 47, 28, 1, 1, 47, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 84, 78, 83, 1, 23, 20, 1, 77, 85, 77, 77, 1, 44, 74, 43, 20, 28, 74, 1, 32, 45, 20, 23, 47, 30, 1, 20, 74, 20, 43, 23, 1, 28, 30, 1, 26, 24, 1, 34, 28, 30, 1, 44, 34, 30, 40, 1, 46, 20, 1, 28, 20, 45, 33, 1, 70, 23, 20, 21, 74, 1, 20, 31, 1, 23, 20, 74, 45, 1, 20, 44, 20, 32, 1, 1, 77, 84, 84, 81, 1, 21, 20, 1, 1, 23, 31, 30, 74, 45, 1, 33, 28, 46, 1, 15, 45, 1, 47, 20, 30, 28, 1, 15, 43, 20, 45, 1, 77, 84, 82, 78, 1, 23, 20, 1, 77, 76, 76, 1, 44, 74, 43, 74, 1, 32, 45, 20, 23, 47, 30, 1, 20, 74, 20, 19, 46, 1, 15, 30, 1, 21, 47, 28, 1, 1, 47, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 85, 77, 77, 1, 23, 20, 1, 77, 84, 85, 77, 1, 23, 20, 1, 77, 84, 78, 84, 1, 44, 74, 43, 20, 28, 74, 1, 32, 45, 20, 23, 47, 30, 1, 20, 74, 20, 43, 23, 1, 44, 74, 31, 20, 45, 20, 43, 1, 28, 30, 1, 32, 45, 20, 74, 1, 20, 74, 20, 43, 20, 23, 1, 44, 23, 26, 28, 46, 1, 15, 44, 30, 74, 70, 20, 1, 21, 47, 28, 1, 0, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 20, 67, 1, 20, 44, 1, 20, 32, 1, 40, 74, 32, 23, 74, 44, 74, 0, 0, 20, 67, 1, 20, 44, 1, 20, 32, 1, 20, 32, 1, 40, 74, 30, 47, 32, 1, 1, 77, 85, 77, 1, 1, 74, 70, 1, 70, 33, 23, 74, 1, 21, 47, 28, 1, 70, 46, 1, 36, 47, 43, 1, 15, 45, 1, 21, 47, 28, 1, 1, 20, 74, 45, 1, 70, 33, 23, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 84, 82, 82, 1, 32, 20, 27, 23, 46, 1, 33, 28, 1, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 65, 20, 25, 30, 1, 20, 36, 43, 20, 31, 74, 1, 27, 47, 20, 32, 23, 1, 0, 0, 28, 30, 1, 44, 30, 28, 20, 21, 1, 41, 30, 20, 30, 1, 74, 70, 1, 20, 23, 47, 43, 74, 28, 20, 45, 1, 70, 47, 32, 20, 45, 74, 1, 32, 46, 1, 38, 35, 47, 1, 45, 46, 20, 74, 1, 28, 20, 38, 33, 20, 45, 74, 45, 1, 44, 32, 23, 74, 1, 72, 74, 30, 28, 1, 1, 20, 41, 28, 20, 43, 21, 20, 45, 28, 1, 23, 47, 20, 45, 28, 1, 44, 74, 1, 27, 47, 20, 46, 1, 70, 46, 1, 21, 46, 1, 41, 32, 43, 20, 21, 1, 65, 32, 1, 20, 32, 23, 1, 1, 20, 34, 43, 20, 26, 74, 1, 20, 74, 45, 1, 44, 41, 20, 44, 1, 28, 30, 1, 45, 74, 44, 46, 1, 20, 24, 43, 1, 20, 45, 25, 20, 44, 1, 20, 32, 23, 1, 23, 35, 46, 30, 1, 23, 47, 40, 22, 74, 43, 1, 44, 74, 1, 33, 47, 28, 1, 1, 21, 46, 1, 28, 30, 1, 77, 79, 81, 76, 1, 25, 20, 45, 74, 20, 1, 72, 30, 47, 46, 1, 28, 20, 30, 28, 45, 1, 70, 46, 1, 38, 20, 45, 74, 1, 34, 26, 23, 74, 20, 45, 1, 44, 74, 1, 33, 47, 28, 1, 1, 20, 74, 45, 1, 28, 30, 1, 28, 27, 23, 46, 1, 20, 32, 23, 1, 1, 20, 74, 45, 1, 20, 32, 23, 1, 70, 46, 1, 28, 30, 1, 32, 20, 43, 1, 77, 84, 79, 81, 83, 1, 23, 47, 34, 74, 1, 21, 46, 1, 34, 47, 30, 23, 1, 31, 28, 46, 1, 20, 74, 1, 44, 25, 43, 32, 1, 20, 47, 1, 45, 74, 20, 31, 1, 45, 37, 20, 44, 74, 1, 30, 20, 1, 21, 20, 31, 44, 20, 45, 74, 1, 70, 45, 45, 47, 45, 1, 21, 46, 1, 20, 32, 43, 32, 23, 20, 74, 74, 1, 65, 74, 33, 1, 32, 45, 20, 23, 47, 30, 1, 20, 74, 20, 43, 23, 1, 32, 45, 20, 23, 47, 30, 1, 32, 45, 20, 23, 47, 30, 1, 20, 74, 20, 43, 23, 1, 65, 30, 47, 45, 74, 45, 1, 28, 30, 1, 32, 45, 20, 74, 1, 20, 74, 20, 43, 20, 23, 1, 44, 23, 26, 28, 46, 1, 15, 44, 30, 74, 70, 20, 1, 20, 74, 20, 43, 20, 23, 1, 44, 23, 26, 28, 46, 1, 15, 44, 30, 74, 70, 20, 1, 21, 47, 28, 1, 0, 0, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 74, 47, 20, 32, 1, 20, 32, 1, 32, 74, 1, 20, 32, 1, 65, 74, 44, 20, 67, 1, 1, 25, 74, 1, 20, 32, 1, 20, 32, 1, 65, 74, 1, 84, 76, 1, 0, 0, 74, 47, 20, 32, 1, 20, 32, 1, 20, 43, 78, 82, 1, 1, 19, 74, 1, 1, 77, 84, 82, 77, 1, 1, 74, 70, 1, 70, 33, 23, 74, 1, 20, 32, 23, 1, 70, 46, 1, 36, 47, 43, 1, 15, 45, 1, 44, 74, 1, 21, 20, 33, 28, 1, 1, 20, 74, 45, 1, 70, 33, 23, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 84, 80, 78, 1, 32, 20, 27, 23, 46, 1, 33, 28, 1, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 74, 47, 20, 32, 1, 20, 32, 1, 21, 30, 20, 45, 47, 72, 47, 43, 81, 79, 78, 77, 1, 0, 0, 74, 47, 20, 32, 1, 20, 32, 1, 32, 21, 20, 32, 1, 77, 76, 82, 78, 82, 1, 1, 74, 70, 1, 70, 33, 23, 74, 1, 21, 47, 28, 1, 70, 46, 1, 36, 47, 43, 1, 15, 45, 1, 21, 47, 28, 1, 1, 20, 74, 45, 1, 70, 33, 23, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 85, 81, 81, 80, 1, 32, 20, 27, 23, 46, 1, 33, 28, 1, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 74, 47, 20, 32, 1, 20, 32, 1, 43, 74, 45, 44, 1, 1, 15, 43, 20, 21, 30, 20, 28, 1, 1, 77, 84, 83, 82, 1, 1, 74, 70, 1, 70, 33, 23, 74, 1, 21, 47, 28, 1, 70, 46, 1, 36, 47, 43, 1, 15, 45, 1, 21, 47, 28, 1, 1, 20, 74, 45, 1, 70, 33, 23, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 84, 83, 82, 1, 32, 20, 27, 23, 46, 1, 33, 28, 1, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 20, 67, 1, 20, 44, 1, 20, 32, 1, 23, 47, 44, 74, 33, 74, 1, 32, 45, 20, 23, 47, 30, 1, 32, 20, 21, 41, 1, 38, 35, 47, 1, 26, 31, 21, 1, 28, 43, 74, 23, 47, 30, 1, 32, 45, 20, 23, 47, 30, 1, 32, 20, 21, 41, 1, 38, 35, 47, 1, 26, 31, 19, 32, 1, 26, 70, 47, 44, 1, 26, 43, 20, 23, 1, 20, 74, 20, 43, 20, 23, 1, 44, 23, 26, 28, 46, 1, 15, 44, 30, 74, 70, 20, 1, 21, 47, 28, 1, 0, 0, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 20, 32, 1, 20, 32, 1, 74, 47, 32, 47, 32, 1, 65, 28, 20, 44, 1, 1, 28, 74, 1, 77, 76, 81, 1, 0, 0, 74, 47, 20, 32, 1, 20, 32, 1, 32, 43, 20, 44, 1, 1, 20, 32, 1, 70, 74, 23, 30, 44, 46, 1, 1, 77, 76, 76, 1, 1, 74, 70, 1, 70, 33, 23, 74, 1, 21, 47, 28, 1, 70, 46, 1, 36, 47, 43, 1, 15, 45, 1, 21, 47, 28, 1, 1, 20, 74, 45, 1, 70, 33, 23, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 69, 74, 1, 77, 85, 77, 84, 81, 1, 32, 20, 27, 23, 46, 1, 33, 28, 1, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 20, 67, 1, 20, 44, 1, 20, 32, 1, 21, 74, 43, 44, 1, 1, 28, 74, 1, 78, 76, 85, 1, 0, 0, 20, 67, 1, 20, 44, 1, 20, 32, 1, 21, 74, 1, 1, 78, 84, 82, 82, 1, 1, 74, 70, 1, 70, 33, 23, 74, 1, 21, 47, 28, 1, 70, 46, 1, 36, 47, 43, 1, 15, 45, 1, 21, 47, 28, 1, 1, 20, 74, 45, 1, 70, 33, 23, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 83, 85, 77, 1, 32, 20, 27, 23, 46, 1, 33, 28, 1, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 20, 45, 1, 20, 32, 23, 46, 1, 65, 69, 20, 74, 1, 79, 81, 1, 0, 0, 20, 67, 1, 20, 44, 1, 20, 32, 1, 45, 43, 20, 45, 74, 47, 43, 74, 20, 1, 1, 77, 77, 83, 82, 1, 1, 74, 70, 1, 70, 33, 23, 74, 1, 21, 47, 28, 1, 70, 46, 1, 36, 47, 43, 1, 15, 45, 1, 21, 47, 28, 1, 1, 20, 74, 45, 1, 70, 33, 23, 74, 1, 28, 30, 1, 32, 20, 43, 1, 77, 85, 79, 77, 1, 32, 20, 27, 23, 46, 1, 33, 28, 1, 0, 0, 0, 0, 38, 45, 47, 20, 45, 1, 44, 41, 20, 43, 46, 1, 1, 74, 47, 20, 32, 1, 20, 32, 1, 77, 83, 79, 1, 0, 0, 74, 47, 20, 32, 1, 20, 74, 1, 20]\n\n\nعنوان مقاله  اچ ام اس سیوتا  اختلاله ۳۵۰ \n\nاچ ام اس اتو  دی۴۴  یک کشتی بود که طول آن 19 بود  بود  این کشتی در سال ۱۹۱۱۸ ساخته شد \n\n\n\nعنوان مقاله  اچ ام اس ف فلرو  ۱۸۱۱ \n\nاچ ام اس ایا ۲۶۱  یک کشتی بود که طول آن بود  این کشتی در سال ۱۸۸۹ ساخته شد \n\n\n\nعنوان مقاله  اچ ام اس وسبیوت  ۱۹۲۸ \n\nاچ ام اس هاداف  ۱۸۹۶  یک کشتی است که طول آن می باشد  این کشتی در سال ۱۹۷۵ ساخته شد \n\n\n\nعنوان مقاله  یواس اس بکل  اس پس ادپایرینگ  ۱۷۶ \n\nیواس اس کونو  ۱۱۷۶  یک کشتی بود که طول آن بود  این زیردریایی در سال ۱۷۵۶ ساخته شد \n\n\n\nعنوان مقاله  اچ اس بینوپتر\n\nای کشتی سناتور سابق عضو حزب دموکی در سال ۱۹۰۳ ساخته شد \n\n\n\nعنوان مقاله  از ۳۶۱\n\nجان  از وی برارد  آلود که سلطه ارشمزار نوع و طور یک گفت شخص تا گروه ایجاد ۵۲ \n\n\n\nعنوان مقاله  اچ ام اسکلفو  اس۱۱۳ \n\nیواس اس ۳ یک زیردریایی بود که طول آن بود  این زیردریایی در سال ۱۸۴۱ ساخته شد \n\n\n\nعنوان مقاله  اچ ام اس در  ۱۸۲۳ \n\nاچ ام اس وم ۷۷۱\n\nاچ ام اس نکسیون\n\nاس اس سله  روپیامان  ۱۸۵۰  یک کشتی بود که طول آن بود \n\n\nعنوان مقاله  آرولدی متر ای پیاکلآوپ\n\nپنجوی یک تعالیات سناتور سابق عضو حفافه مد و به خوود دلای آیتوسط ایالت شماره وستانة دار \n\nیواس سی نینگه  حضور  به تورکتشی بر نوع دستگواه مفهوم تقش و  بین ابحی اصوط ارانی مقناق شده و رامانی خاندپری وی  یاکس        حمل \nدر این کاران برقات اعلی است  چشمارم است  آسی است  اروپتس فالیزه پل هایشگرتی می شود  آن روی تاان شناست اوامیک پهتال جاسک است  سینمار می به فرداوان کارتی محرز های مهمر روستان  آنونی   خلی و افزای از عدم خالیات گردد  فیلم در از تقوت ارتفاع تا مرتباره ادر حلب ارندویمه  پایزیان شدم در سال ۱۳۰۱ به طول مربوط  دایت ابتدخاران در زمان دائلگی و غرنبار بهپتهان بود \n\n\n\n\n\nعنوان مقاله  عنبوذل\n\nپتروش اندیبیلر یک کلاه اتراکید همچنین که یک شبکه  ضعت مرحلد شد  اقدای هم تاریان مهم بین شیل سنناتور ایالت و در سنای ایالات متحده آمریکا بود \n\n\n\n\n\nعنوان مقاله  وی واجریت  آنوری اندثاوت جمله آمریکا خواهد آمریکا بود  وی در سال ۱۹۷۴ تا ۱۹۱۴ میلادی سناتور ایالت صحابی در سنای ایالات متحده آمریکا بود  وی در سال ۱۸۸۹ تا ۱۸۵۷ میلادی سناتور ایالت زیادی ایران این تلوم  ال است \n\n\nعنوان مقاله  اچ ام اس گرمما  ۱۸۹۵۵ \n\nیواس اس کان  تی بی \n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-06-09T17:04:14.710385Z","iopub.execute_input":"2024-06-09T17:04:14.711230Z","iopub.status.idle":"2024-06-09T17:04:14.715634Z","shell.execute_reply.started":"2024-06-09T17:04:14.711188Z","shell.execute_reply":"2024-06-09T17:04:14.714777Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef perpl_rouge():\n    model.eval()\n    r1 = []\n    r2 = []\n    p = []\n    num_batches = 50\n    for i, (X, Y) in enumerate(val_dataloader):\n        X=X.to(device)\n        Y=Y.to(device)\n        logits, loss = model(X, Y)\n        p.append(2**(loss.item()))\n        \n    \n        context = X[0].unsqueeze(0)\n        pred = train_dataset.decode(m.generate(context, max_new_tokens=64)[0].tolist())\n        print('expected: ', train_dataset.decode(context[0].tolist()))\n        print('predicted: ' , pred)\n        for j in range(batch_size):\n            context = X[j].unsqueeze(0)\n            pred = train_dataset.decode(m.generate(context, max_new_tokens=64)[0].tolist())\n            scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n            scores = scorer.score(train_dataset.decode(context[0].tolist()), pred)\n            r1.append(scores['rouge1'].recall)\n            r2.append(scores['rouge2'].recall)\n        \n        if i + 1 >= num_batches:\n            break\n            \n    r1 = np.array(r1).mean()\n    r2 = np.array(r2).mean()\n    p = np.array(p).mean()\n\n    return r1,r2,p\n\nprint(perpl_rouge())","metadata":{"execution":{"iopub.status.busy":"2024-06-09T17:04:16.654714Z","iopub.execute_input":"2024-06-09T17:04:16.655483Z","iopub.status.idle":"2024-06-09T17:15:38.049172Z","shell.execute_reply.started":"2024-06-09T17:04:16.655446Z","shell.execute_reply":"2024-06-09T17:15:38.048071Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"expected:  یو بیشتر منطقی و تابع نظم و قاعده  ویژه ای هستند که قبلا  توسط ه\npredicted:  یو بیشتر منطقی و تابع نظم و قاعده  ویژه ای هستند که قبلا  توسط هر مسرمولگی گذارد کلیلین نمادار شرکت های قراری متمام کوربوگرای ها\nexpected:  ت به آن ها به عنوان شکلی از تنبیه می نگرند  این حکم به کشور تضمی\npredicted:  ت به آن ها به عنوان شکلی از تنبیه می نگرند  این حکم به کشور تضمیکر به عبه شناسی عبارت جایز در مورد ماندار این ساختر نوشته بوده ا\nexpected:  ن حلال  به قطبیت انعطاف پذیر آب وابسته است که آن هم مستقیما  به \npredicted:  ن حلال  به قطبیت انعطاف پذیر آب وابسته است که آن هم مستقیما  به عنوان قرار ازدا بویال جابرجی می شد  به ویندرد\n\nدر محبق دوره از م\nexpected:  زی الگوریتم تصادفی بسیار ساده تری را بر اساس تعمیم الگوریتم تصاد\npredicted:  زی الگوریتم تصادفی بسیار ساده تری را بر اساس تعمیم الگوریتم تصادت بخش کمکن می کند  در طر اکی لالمی های نیز جری در سلطان با یا نج\nexpected:  ل اگر نمونه ۳ بخشی قابل حل باشد  مسئله افراز  1  نیز در گراف   ب\npredicted:  ل اگر نمونه ۳ بخشی قابل حل باشد  مسئله افراز  1  نیز در گراف   بازیگرهای بیمه هم سرای انواع برای اش سور نفر  تهمز ارتفاع به آن  \nexpected:    برای خانواده  صلح بانان استرس زا می باشد \n\nدیدگاه دیگری ناظر ب\npredicted:    برای خانواده  صلح بانان استرس زا می باشد \n\nدیدگاه دیگری ناظر بود تاون فیلمور آنج  \nبرگلی اوس پیکا در سناتور سابق عضو حزب دموکر\nexpected:   احداث شده است که قدمت آن به اواخر دوره قاجار برمی گردد  این خان\npredicted:   احداث شده است که قدمت آن به اواخر دوره قاجار برمی گردد  این خانواد مهمه  ممهرمت \n\nدر ۲۴ مون ۱۴۱۰ اف ۸۹۹۹ به نقل گفت  یا فرقی و \nexpected:  اهرات بیرونی شخصیت و رفتارهای فردی انسان است  خطوط بیانگر می توا\npredicted:  اهرات بیرونی شخصیت و رفتارهای فردی انسان است  خطوط بیانگر می تواند  مترهای سه پایته دریاسلاری از هم حتی  محدحل اس داشته ماد که ج\nexpected:  ی پیروان نیز هست  بر خلاف مدل احتمالی فیدلر  مدل مسیر هدف بیان م\npredicted:  ی پیروان نیز هست  بر خلاف مدل احتمالی فیدلر  مدل مسیر هدف بیان معطل ایران است و موجب طول آن می باشد \n\n\n\nعنوان مقاله  مقدداس سیاس\nexpected:    تغییرات چشمگیر اقتصادی و تکنولوژیکی باعث ایجاد دومین پرونده عظ\npredicted:    تغییرات چشمگیر اقتصادی و تکنولوژیکی باعث ایجاد دومین پرونده عظیری استفاده شود  اطلاعات انتخاب موسطح استم اسلام مورد سمت های ا \nexpected:  ی ایجاد می شوند  پادتن های تک تیره اتصال تک ظرفیتی دارند بدین مع\npredicted:  ی ایجاد می شوند  پادتن های تک تیره اتصال تک ظرفیتی دارند بدین معمورات بسیار بخش تا خبرده جاس مستشمد  این اولینولوگ ردادان  فعالی\nexpected:  اتین بازیلیکا  برگرفته از کلمه یونانی     به کلیساهای مهم و بزرگ\npredicted:  اتین بازیلیکا  برگرفته از کلمه یونانی     به کلیساهای مهم و بزرگ کارند می توانی گایین بازیگ کی عمارتل باست و و بد نیاز اهل اجسای\nexpected:  ت  است که نشانگر توانایی رهبر در ایجاد رابطه بین فردی با پیروان \npredicted:  ت  است که نشانگر توانایی رهبر در ایجاد رابطه بین فردی با پیروان قهتیه غذار بازی خود گسترده  در تصویر خواهای قصویت بسیارک است  اخ\nexpected:  ه جای دستکاری بازار از پشت صحنه توسط شرکت های خصوصی قدرتمند به س\npredicted:  ه جای دستکاری بازار از پشت صحنه توسط شرکت های خصوصی قدرتمند به سال  به می باشده  ۱۹۲۴۶  ۹۸۲۲  میلادی سناتور ایالت پیادی ایران اس\nexpected:   نخستی سانان  آغازیان  مورد مطالعه قرار گرفته است  بنگرید به فرا\npredicted:   نخستی سانان  آغازیان  مورد مطالعه قرار گرفته است  بنگرید به فرانی به شتش دورمش  سوزه ۱۳۸۰ بسیار شد  متحده ۱ میلادی هجر قرن ارشا\nexpected:     بعدی نیز به مرتبه      کاهش می یابد \n\nدرختهای محدوده می توانن\npredicted:     بعدی نیز به مرتبه      کاهش می یابد \n\nدرختهای محدوده می توانناد آمریکا  زاهداریایه آنها تحت  بسی متولد ترنظیر است  مشاملی پیش\nexpected:  تمی\n\nاسپیرال لگاریتمی یا مارپیچ لگاریتمی یا اسپیرال متساوی الزاو\npredicted:  تمی\n\nاسپیرال لگاریتمی یا مارپیچ لگاریتمی یا اسپیرال متساوی الزاوه   تولید  آن به فردیل حفظی از طرف یک کنیور در و۹۸۸ ما سیتد لومب\nexpected:  دانشجویان سفیدپوست دانشگاه فیسک را دوره کردند و با یک چمدان آنقد\npredicted:  دانشجویان سفیدپوست دانشگاه فیسک را دوره کردند و با یک چمدان آنقدون هستند   فاست  عموم ترین لمه ۱۱۸۲۰ ژنده دهند که هید و را جزازا\nexpected:  کوب توسط پلیس و فعالیت های تروریستی کوکلوس کلان ها در بیرمنگام  \npredicted:  کوب توسط پلیس و فعالیت های تروریستی کوکلوس کلان ها در بیرمنگام  پاکس سید  است  استفاده از گیانی کتاب است که معمارش کشور یورید\n\nد\nexpected:  تیجه یکسان به دست آمده نشان می دهد هر گراف مسطح با درجه متناهی ت\npredicted:  تیجه یکسان به دست آمده نشان می دهد هر گراف مسطح با درجه متناهی توم دادن این مسابق شده اند کردن   باقی حافظ میرده اند  بر موسط نا\nexpected:  ه قیمت  صاحبان خطوط راه آهن به ادغام شدن به عنوان راهی برای از ب\npredicted:  ه قیمت  صاحبان خطوط راه آهن به ادغام شدن به عنوان راهی برای از برای نفی همکن معار بود \n\n\n\n\nعنوان مقاله  فجی  ۲۸ \n\nکل سودگی   پس \nexpected:  تاییان را از داشتن جنگ افزار منع کردند و همین باعث شد که جنگ افز\npredicted:  تاییان را از داشتن جنگ افزار منع کردند و همین باعث شد که جنگ افزارد  مول اسپید سلاری در را کند \n\nاین زندگی را مختلف حکمیده خود ع\nexpected:  دقیق تر خودکار در دست به هنگام نوشتن می شود  برای یکسان شدن فشار\npredicted:  دقیق تر خودکار در دست به هنگام نوشتن می شود  برای یکسان شدن فشار های کارد رایت داشتن شده است  آن شر کشور است که تقدا نسلنات در س\nexpected:  دست می آورند  و از یک دغدغه کلی مبنی بر حفظ روابط اجتماعی مثبت و\npredicted:  دست می آورند  و از یک دغدغه کلی مبنی بر حفظ روابط اجتماعی مثبت وجود روی آمد رفت \n\n\n\n\nنقش بزرگ زاده ها دادگاه این شبکه و کتاب خار\nexpected:  رفتند  صدها نفر از شهروندان محلی دستگیر شدند  و هربرت لی  یکی از\npredicted:  رفتند  صدها نفر از شهروندان محلی دستگیر شدند  و هربرت لی  یکی از است که طول آن می باشد  این کشتی در سال ۱۹۰۲ ساخته شد \n\n\n\nعنوان \nexpected:  ن ها برای نوشتن  مطالعه  آشپزی  خیاطی و هر آنچه نیاز به دقت و تم\npredicted:  ن ها برای نوشتن  مطالعه  آشپزی  خیاطی و هر آنچه نیاز به دقت و تمام کلی کرده است  بر ما آمازی و با ایجاد مجموعه پاگیر  تحذفیت عنی\nexpected:  وتو متولد ۲۶ می ۱۹۶۸ در کائوآئی  هاوایی است  او یک ترازن است \n\n\n\npredicted:  وتو متولد ۲۶ می ۱۹۶۸ در کائوآئی  هاوایی است  او یک ترازن است \n\n\n\n\nعنوان مقاله  دی سناتور سابق عضو حزب دموکرات ایالات متحده آمریک\nexpected:  یت می کند که باید رمزوراز یک داستان کارآگاهی را حل کند  او بی ای\npredicted:  یت می کند که باید رمزوراز یک داستان کارآگاهی را حل کند  او بی این ۱۳۴ با ۲۰۱ بترین تصویر مدایست و مرضی  اول سناتور سابق عضو حزب \nexpected:  ه در   متناظر یک مجموعه چیره یالی در گراف   است  بنابراین اندازه\npredicted:  ه در   متناظر یک مجموعه چیره یالی در گراف   است  بنابراین اندازه  نوجید اولین محمدال هم برنامه  چرزم بررگ را پی دهند کرداری  ساط\nexpected:  ا ویژگی مشخص که بین دو یا چند بوم سازگان  اکوسیستم  یا دو یا چند\npredicted:  ا ویژگی مشخص که بین دو یا چند بوم سازگان  اکوسیستم  یا دو یا چند  مدندان گز آن بود  تیم پشتامه ساخت مقادی  تراض شد  اما سال ۲۰۰۰\nexpected:  ناهی ندارد  مگر اینکه   تئوری جداسازی گراف مسطح تأکید می کند که \npredicted:  ناهی ندارد  مگر اینکه   تئوری جداسازی گراف مسطح تأکید می کند که کاربری به دست گیاه هار یاهو مدیدن معلم از ۳٫۷۸ مایه ای الامی پوز\nexpected:  لحاظ زمین شناسی به مناطق خاص جغرافیایی  که دارای شرایط یکسان از \npredicted:  لحاظ زمین شناسی به مناطق خاص جغرافیایی  که دارای شرایط یکسان از پیش استفاده بود  بود  این کشتی در سال ۱۹۱۱ ساخته شد \n\n\n\nعنوان مق\nexpected:  ان های خوب مکان خشنی است و آنهایی که در این صنعت هستند همه  حقیق\npredicted:  ان های خوب مکان خشنی است و آنهایی که در این صنعت هستند همه  حقیقات دارای ایالات متحده آمریکا متحده است \n\n\n\n\n\nعنوان مقاله  آروجوی\nexpected:  گفت   ما نه تنها منکر حق شخصی و گروهی برای دفاع از خود علیه تهاج\npredicted:  گفت   ما نه تنها منکر حق شخصی و گروهی برای دفاع از خود علیه تهاجس هم گورانی مادند  جهته مونزرهای کاهشن و ماجرای توسط تحسایت بردو\nexpected:  می دهد که معمولا  فقط حدود ۵ تا ۲۰ درصد از جواب بهینه بزرگتر است\npredicted:  می دهد که معمولا  فقط حدود ۵ تا ۲۰ درصد از جواب بهینه بزرگتر است تر در ایران ۲۰۱۰ به سال بزرگ گسترال حرفه و علین دارد در زمان نظ\nexpected:  بستان آزادی  رسانه های خبری ملی توجه کمی به آزار و اذیت رای دهند\npredicted:  بستان آزادی  رسانه های خبری ملی توجه کمی به آزار و اذیت رای دهندگیری انگلی دیگر اطملاع فراهیست اعقول در  غولات راه داعشقات ژنش ر\nexpected:  مهم این است که جوایز متناسب با شأن این ورزش بوده و پشتوانه ای بر\npredicted:  مهم این است که جوایز متناسب با شأن این ورزش بوده و پشتوانه ای برای دو نیاز مساحت جوارید و هوشتی آرام تقریبان های محفورایی توجهی \nexpected:  رباره  مجموعه  چیره از دهه  ۱۹۵۰ آغاز شدند و در میانه  ۱۹۷۰ با ب\npredicted:  رباره  مجموعه  چیره از دهه  ۱۹۵۰ آغاز شدند و در میانه  ۱۹۷۰ با به نموده اید  به جیمز به مرزارهی در سینما بر داپیز قرار بالات که \nexpected:  ه های سنی جذابیت داشته باشد  کشتی با چوخه همیشه در فضای باز و دل\npredicted:  ه های سنی جذابیت داشته باشد  کشتی با چوخه همیشه در فضای باز و دلیل با دایرای برنامه هواگان اسفری   ای یکی اس اس آپا  ۱۹۷۱  طر مس\nexpected:  بودنش با گوتیک فرانسوی تفاوت دارد \n\nنقشه  کلیسای سالزبری راست خط\npredicted:  بودنش با گوتیک فرانسوی تفاوت دارد \n\nنقشه  کلیسای سالزبری راست خطورتی بعد صورت ونامین قربارها  تران را داده می شود  به کمکانی کدک\nexpected:  رفتن حالت هستند  سودی که بدست می آید اگر یکی از بازیکنان تصمیم ب\npredicted:  رفتن حالت هستند  سودی که بدست می آید اگر یکی از بازیکنان تصمیم به واخل معمام 30 \nگیردور تشکس تفستا کرای هستند  فرادارات به در کا\nexpected:  افتن گنج های پنهان کندوکاو شدند  زیرا روستاییان ت رک و ک رد منطق\npredicted:  افتن گنج های پنهان کندوکاو شدند  زیرا روستاییان ت رک و ک رد منطقه  بار سلگر تحت  ام وی مرداعات شده باعث باشد  پوشی او  ۲۰۱ تاید \nexpected:   و قدیمی شده است \n\nبرای اولین بار در سال ۱۹۱۲ میلادی جراح دانمار\npredicted:   و قدیمی شده است \n\nبرای اولین بار در سال ۱۹۱۲ میلادی جراح دانماری قدر آمادای و برخی و است و ۶ قارند در آن دوز برای علقام گه های \nexpected:   هر سه سطح فدرال  کشوری و محلی  مجبور بودند بلافاصله به این شرای\npredicted:   هر سه سطح فدرال  کشوری و محلی  مجبور بودند بلافاصله به این شرایط کننان باشند  منبوط در روشاه های در این درگاه های کنون قابل جار\nexpected:  الا بیکر دعوت شدند تا در کنفرانسی در دانشگاه شاو   به لحاظ تاریخ\npredicted:  الا بیکر دعوت شدند تا در کنفرانسی در دانشگاه شاو   به لحاظ تاریخ استفاده ها که کردن  تسلفه ای کاران اعمولات کرده و سه مجموعه مسل\nexpected:  انشجویی همکاری های خشونت پرهیز   رابرت موزز  نخستین پروژه ثبت نا\npredicted:  انشجویی همکاری های خشونت پرهیز   رابرت موزز  نخستین پروژه ثبت ناحی در شپ راه در حاضه قرار باشد رایال می شوند  که جهانیا قابل علی\nexpected:  سیاه پوست که به دنبال حق رای  تحصیل در مدارس آزاد و سازمان دهی ح\npredicted:  سیاه پوست که به دنبال حق رای  تحصیل در مدارس آزاد و سازمان دهی حال ایران می کند \n\n\n\n\nعنوان مقاله  مجلی اس اس ایپازیلرون\n\nدیو ای \nexpected:   سراب و سخر علیا و همچنین در اسدآباد روستایی کووانج  ۱۰   دسنن ی\npredicted:   سراب و سخر علیا و همچنین در اسدآباد روستایی کووانج  ۱۰   دسنن یک آن ۲۶۰۹ م\n\nکونون سر سال 10           ۱۷۴۵ آپال ۹۹۱۸ \n\nاچ ام اس\nexpected:  د  ترکیب بند او در منقبت علی  ع  در دست می باشد که در آن به روشن\npredicted:  د  ترکیب بند او در منقبت علی  ع  در دست می باشد که در آن به روشن بازج هوارها او مجلس نفر سناتور سابق عضو حزب دموکرات ایالات متحد\nexpected:  ار شد  وی در سال ۱۳۵۶ پنج قسمت از سریال چنگک و فیلم بلندی به نام\npredicted:  ار شد  وی در سال ۱۳۵۶ پنج قسمت از سریال چنگک و فیلم بلندی به نام کارگری هنر محسنات می شوند \n\nدر سال ۱۹۱۸ اصلی  مالک به دوره زین \n(0.0140625, 0.00375, 3.7022191074625392)\n","output_type":"stream"}]}]}